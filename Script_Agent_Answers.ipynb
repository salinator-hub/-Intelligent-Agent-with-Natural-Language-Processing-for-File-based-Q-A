{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af3aff48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask a question (or 'q' to quit): how\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Agent's answer: wiaaigaagikypdngma4fdqqouhe28uaxdu0ofi9qehjvvghm8ghv8blpaewicdnzutkfxly5pyjg8sb4vsailaazcwwqgf0madglcaa0cub0\n",
      "Ask a question (or 'q' to quit): what is GAn\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "Agent's answer: nonpuwwcxotvpj5f7tdjugdapukiyk5xk5lxxf7xbd5\n",
      "Ask a question (or 'q' to quit): SO GAN\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Agent's answer: qaiosaq20azqcyjpeq7d0auleah2iafcsgix0avuidtxyaymaac6uadwjikekajcuaa0ywmuwasdmnnuuj\n",
      "Ask a question (or 'q' to quit): agent\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "Agent's answer: cgge9eejubaddcabtyebvnmqgsacrnahjvb5lfnm5jaoybejyiafvmafbdaik5alxdanpgffpgqq4jamrfailybhfpaem\n",
      "Ask a question (or 'q' to quit): q\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Create a language model\n",
    "def create_language_model(vocab_size, max_sequence_length, embedding_dim, lstm_units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "    model.add(LSTM(units=lstm_units))\n",
    "    model.add(Dense(units=vocab_size, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Load files for the agent to understand\n",
    "def load_files(file_paths):\n",
    "    files = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as file:\n",
    "            file_content = file.read()\n",
    "            files.append(file_content)\n",
    "    return files\n",
    "\n",
    "# Create an agent\n",
    "def create_agent():\n",
    "    agent = {}\n",
    "    agent['files'] = []\n",
    "    return agent\n",
    "\n",
    "# Update the agent with uploaded files\n",
    "def update_agent(agent, file_paths):\n",
    "    files = load_files(file_paths)\n",
    "    agent['files'].extend(files)\n",
    "\n",
    "# Generate an answer from the agent\n",
    "def generate_answer(agent, question, tokenizer, model, max_sequence_length):\n",
    "    input_text = '\\n'.join(agent['files']) + '\\n' + question\n",
    "    encoded_input = tokenizer.texts_to_sequences([input_text])\n",
    "    padded_input = pad_sequences(encoded_input, maxlen=max_sequence_length)\n",
    "    predictions = model.predict(padded_input)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    generated_text = tokenizer.index_word[predicted_index]\n",
    "    return generated_text\n",
    "\n",
    "# Main script\n",
    "def main():\n",
    "    agent = create_agent()\n",
    "\n",
    "    # User uploads files\n",
    "    file_paths = [r'C:\\Users\\salil\\Downloads\\dcgan.ipynb']\n",
    "    update_agent(agent, file_paths)\n",
    "\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(agent['files'])\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "    max_sequence_length = 1000\n",
    "    embedding_dim = 100\n",
    "    lstm_units = 128\n",
    "\n",
    "    model = create_language_model(vocab_size, max_sequence_length, embedding_dim, lstm_units)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    while True:\n",
    "        # User asks a question\n",
    "        question = input(\"Ask a question (or 'q' to quit): \")\n",
    "        if question == 'q':\n",
    "            break\n",
    "\n",
    "        # Agent generates an answer\n",
    "        answer = generate_answer(agent, question, tokenizer, model, max_sequence_length)\n",
    "        print(\"Agent's answer:\", answer)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1c3ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
